{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading datasets\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import measure #supports video also\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from utils.io import figure_save\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import logging\n",
    "import time\n",
    "from utils.io import imshow\n",
    "\n",
    "from utils.Network import Network\n",
    "from utils.Analyser import Analyser\n",
    "from utils.io import save_network, save, load, figure_save, load_network, make_folder_results, imshow\n",
    "from utils.format import hex_str2bool\n",
    "from utils.WaveDataset import create_datasets, transformVar\n",
    "\n",
    "logging.basicConfig(format='%(message)s',level=logging.INFO)\n",
    "channels=1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nr_net = 0 \n",
    "\n",
    "version = nr_net + 10\n",
    "network_type = \"7_kernel_3LSTM/\"\n",
    "\n",
    "if 'Darwin' in platform.system():\n",
    "    data_dir = './'\n",
    "else:\n",
    "    data_dir = '/disk/scratch/s1680171/wave_propagation/'\n",
    "\n",
    "if not os.path.isdir(\"./Results\"):\n",
    "    os.mkdir(\"./Results\")\n",
    "results_dir = \"./Results/\" + network_type \n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    make_folder_results(results_dir)\n",
    "    \n",
    "# Data\n",
    "filename_data = results_dir + \"all_data.pickle\"\n",
    "if os.path.isfile(filename_data):\n",
    "    logging.info('Loading datasets')\n",
    "    all_data = load(filename_data)\n",
    "    train_dataset = all_data[\"Training data\"]\n",
    "    val_dataset = all_data[\"Validation data\"]\n",
    "    test_dataset = all_data[\"Testing data\"]\n",
    "else:\n",
    "    logging.info('Creating new datasets')\n",
    "    test_dataset, val_dataset, train_dataset = create_datasets(\n",
    "         data_dir+\"Video_Data/\", transformVar, test_fraction=0.15, validation_fraction=0.15, check_bad_data=False, channels=channels)\n",
    "    all_data = {\"Training data\": train_dataset, \"Validation data\": val_dataset, \"Testing data\": test_dataset}\n",
    "    save(all_data, filename_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.root_dir = './Video_Data/'\n",
    "val_dataset.root_dir = './Video_Data/'\n",
    "test_dataset.root_dir = './Video_Data/'\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "\n",
    "model = Network(device, channels)\n",
    "model = load_network(model, device, results_dir+\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.training import test\n",
    "from utils.Scorekeeper import Scorekeeper\n",
    "from utils.training import initial_input, reinsert, propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test(model, test_dataloader, starting_point, num_input_frames, num_output_frames, \n",
    "#      channels, device, score_keeper, results_dir, plot=True, debug=True)\n",
    "# score_keeper.plot(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=1)\n",
    "starting_point = 0\n",
    "score_keeper=Scorekeeper(results_dir,1)\n",
    "num_input_frames = 5\n",
    "num_output_frames = 10\n",
    "starting_point = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(test_dataloader))\n",
    "# batch_images=batch['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=False\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# seed_everything(seed=12345)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=1)\n",
    "# starting_point = 0\n",
    "# score_keeper=Scorekeeper()\n",
    "# plot=True\n",
    "# debug=True\n",
    "\n",
    "# test(model, test_dataloader, starting_point, num_input_frames, num_output_frames, \n",
    "#      channels, device, score_keeper, results_dir, plot=plot, debug=debug)\n",
    "# score_keeper.plot(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "image_to_plot = 1 # random.randint(0, 15)\n",
    "reinsert_frequency = 10\n",
    "training = False\n",
    "\n",
    "for batch_num, batch in enumerate(test_dataloader):\n",
    "    batch_images = batch[\"image\"]\n",
    "    batch_size = batch_images.size()[0]\n",
    "    model.reset_hidden(batch_size=batch_images.size()[0], training=False)\n",
    "\n",
    "    total_frames = batch_images.size()[1]\n",
    "    num_future_frames = total_frames - (starting_point + num_input_frames)\n",
    "    for future_frame_idx in range(num_future_frames):\n",
    "        if future_frame_idx == 0:\n",
    "            prop_type = 'Initial input'\n",
    "            input_frames = batch_images[:, starting_point * channels:(starting_point + num_input_frames) * channels, :, :].clone()\n",
    "            output_frames, target_frames = initial_input(model, input_frames, batch_images, starting_point, num_input_frames, channels, device, training)\n",
    "        elif (future_frame_idx+1)%reinsert_frequency == 0:\n",
    "            prop_type = 'Reinsert'\n",
    "            input_frames = output_frames[:, -num_input_frames * channels:, :, :].clone()\n",
    "            output_frames, target_frames = reinsert(model, input_frames, output_frames, target_frames, batch_images, \n",
    "                                                            starting_point, num_input_frames, future_frame_idx, channels, device, training)\n",
    "        else:\n",
    "            prop_type = 'Propagate'\n",
    "            output_frames, target_frames = propagate(model, output_frames, target_frames, batch_images, \n",
    "                                                          starting_point, num_input_frames, future_frame_idx,\n",
    "                                                          channels, device, training)\n",
    "            # output & target_frames size is [batches, channels * (n + 1), 128, 128]\n",
    "\n",
    "#         if debug:\n",
    "#             print('batch_num %d\\tfuture_frame_idx %d\\ttype %s' % (batch_num, future_frame_idx, prop_type))\n",
    "#             print(output_frames.size(), target_frames.size())\n",
    "\n",
    "        for ba in range(output_frames.size()[0]):\n",
    "            score_keeper.add(output_frames[ba, -channels:, :, :].cpu(), \n",
    "                             target_frames[ba, -channels:, :, :].cpu(), \n",
    "                             future_frame_idx,\"pHash\", \"pHash2\", \"SSIM\", \"Own\", \"RMSE\")\n",
    "\n",
    "        if plot:\n",
    "            plot_predictions()\n",
    "            plot_cutthrough()\n",
    "\n",
    "    logging.info(\"{:d} out of {:d}\".format(batch_num + 1, len(test_dataloader)))\n",
    "    if debug: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_keeper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from skimage import measure\n",
    "ssim=[]\n",
    "for ba in range(output_frames.size()[0]):\n",
    "    predicted = output_frames[ba,-1:,:,:]\n",
    "    target = target_frames[ba,-1:,:,:]\n",
    "    ssim.append(measure.compare_ssim(score_keeper.prepro(predicted), \n",
    "                                     score_keeper.prepro(target), \n",
    "                                     multichannel=False, gaussian_weights=True))\n",
    "#     score_keeper.add(predicted, target, future_frame_idx,\"SSIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5505233955584922"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 80, 128, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_frames.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6140247413912575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.compare_ssim(score_keeper.prepro(predicted), score_keeper.prepro(target), \n",
    "                     multichannel=False, gaussian_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
