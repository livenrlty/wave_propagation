{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.arg_extract import get_args\n",
    "from utils.experiment_evaluator import evaluate_experiment\n",
    "from utils.experiment import Experiment\n",
    "from argparse import Namespace\n",
    "from utils.experiment_evaluator import image_prepro, create_evaluation_dataloader, get_test_predictions_pairs, save_sequence_plots\n",
    "import os\n",
    "from utils.io import save\n",
    "plt.ioff()\n",
    "from utils.io import load\n",
    "batch_images_all = load('batches.pickle')\n",
    "\n",
    "data_directory = '../experiments_results/'\n",
    "experiments = [dI for dI in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, dI))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dd = {'experiment_name': 'ar_lstm_batch_16_samples_10_in_5_out_20_normal_lr_0.0001_dataset_original_16h_patience_5',\n",
    "#         'num_epochs': 1,\n",
    "#         'num_workers': 1,\n",
    "#         'test_starting_point': 15,\n",
    "#         'num_total_output_frames':80,\n",
    "#         'debug': False}\n",
    "\n",
    "# args_new = Namespace(**dd)\n",
    "# experiment = Experiment(args_new)\n",
    "# experiment.load_from_disk(test=True)\n",
    "    \n",
    "    \n",
    "# dataloaders = {\"Test\": experiment.dataloaders['test'],\n",
    "#                \"Lines\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Lines/'), experiment.args.normalizer_type),\n",
    "#                \"Double_Drop\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Double_Drop/'), experiment.args.normalizer_type),\n",
    "#                \"Illumination_135\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Illumination_135/'), experiment.args.normalizer_type),\n",
    "#                \"Shallow_Depth\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Shallow_Depth/'), experiment.args.normalizer_type),\n",
    "#                \"Smaller_Tub\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Smaller_Tub/'), experiment.args.normalizer_type),\n",
    "#                \"Bigger_Tub\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Bigger_Tub/'), experiment.args.normalizer_type),\n",
    "#                 \"Fixed_Tub\": create_evaluation_dataloader(os.path.join(experiment.dirs['data_base'], 'Fixed_Tub_10/'), experiment.args.normalizer_type)\n",
    "\n",
    "#                }\n",
    "\n",
    "# batch_images_all = {}\n",
    "# for dset, dloader in dataloaders.items():\n",
    "#     it = iter(dloader)\n",
    "#     for i in range(1,4):\n",
    "#         batch_images_all[dset+'_%s'%i] = next(it)\n",
    "        \n",
    "# save(batch_images_all, 'batches.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_all_tests_for_experiment(experiment, exp, belated):\n",
    "    frames = [0, 9, 19, 29, 39, 59, 79]\n",
    "    fig, ax = plt.subplots(int(len(batch_images_all)/3) * 2, len(frames), figsize = (19, 45))\n",
    "\n",
    "    \n",
    "    for i, k in enumerate(list(batch_images_all.keys())[::3]):\n",
    "        batch_images = batch_images_all[k]\n",
    "        output_frames, target_frames = get_test_predictions_pairs(experiment.model, belated, \n",
    "                                                              batch_images, \n",
    "                                                              args_new.test_starting_point-experiment.args.num_input_frames, \n",
    "                                                              args_new.num_total_output_frames)\n",
    "        output_frames = image_prepro(output_frames, experiment.normalizer)\n",
    "        target_frames = image_prepro(target_frames, experiment.normalizer)\n",
    "\n",
    "        t = 0\n",
    "        ax[2*i, t].set_ylabel(k.upper(), rotation=45, fontsize=20)\n",
    "        ax[2*i, t].yaxis.set_label_coords(-0.2,0.5)\n",
    "        ax[2*i, t].get_yaxis().set_ticks([])\n",
    "        ax[2*i, t].spines['top'].set_visible(False)\n",
    "        ax[2*i, t].spines['right'].set_visible(False)\n",
    "        ax[2*i, t].spines['bottom'].set_visible(False)\n",
    "        ax[2*i, t].spines['left'].set_visible(False)\n",
    "        ax[2*i, t].tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False)\n",
    "\n",
    "        ax[2*i+1, t].set_ylabel('Prediction', rotation=45, fontsize=20)\n",
    "        ax[2*i+1, t].yaxis.set_label_coords(-0.2,0.5)\n",
    "        ax[2*i+1, t].get_yaxis().set_ticks([])\n",
    "        ax[2*i+1, t].spines['top'].set_visible(False)\n",
    "        ax[2*i+1, t].spines['right'].set_visible(False)\n",
    "        ax[2*i+1, t].spines['bottom'].set_visible(False)\n",
    "        ax[2*i+1, t].spines['left'].set_visible(False)\n",
    "        ax[2*i+1, t].tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False)\n",
    "\n",
    "        for t in range(len(frames)):\n",
    "            if t > 0:\n",
    "                ax[2*i, t].axis('off')\n",
    "                ax[2*i+1, t].axis('off')\n",
    "            if i == 0:\n",
    "                ax[2*i, t].set_title('t = ' + str(frames[t]+1), fontsize=30)\n",
    "            ax[2*i, t].imshow(target_frames[0, frames[t], :, :], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[2*i+1, t].imshow(output_frames[0, frames[t], :, :], cmap='gray', vmin=0, vmax=1)\n",
    "    #         ax[i,0].set_ylabel('test', rotation = 0)\n",
    "\n",
    "    exp_name = exp + '_belated' if belated else exp\n",
    "    fig.suptitle(exp_name, fontsize=24) # or plt.suptitle('Main title')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.00, top=0.95, wspace=0.05)\n",
    "#     plt.show()\n",
    "    plt.savefig('qualitative/Individual_Models/%s.png'% exp_name, format='png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [e for e in experiments if 'ar_lstm' in e and 'dilated' not in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# experiments.sort()\n",
    "# for exp in experiments:\n",
    "#     print(exp)\n",
    "#     dd = {'experiment_name': exp,\n",
    "#             'num_epochs': 1,\n",
    "#             'num_workers': 1,\n",
    "#             'test_starting_point': 15,\n",
    "#             'num_total_output_frames':80,\n",
    "#             'debug': False}\n",
    "\n",
    "#     args_new = Namespace(**dd)\n",
    "#     experiment = Experiment(args_new)\n",
    "#     experiment.load_from_disk(test=True)\n",
    "    \n",
    "#     plot_all_tests_for_experiment(experiment, exp, belated=False)\n",
    "#     if experiment.args.model_type == 'convlstm' or experiment.args.model_type == 'predrnn':\n",
    "#         plot_all_tests_for_experiment(experiment, exp, belated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_predictions(exp, batch_images):\n",
    "\n",
    "    if 'belated' in exp:\n",
    "        exp = exp[:-8]\n",
    "        belated = True\n",
    "    else:\n",
    "        belated = False\n",
    "\n",
    "#     print(exp)\n",
    "    dd = {'experiment_name': exp,\n",
    "            'num_epochs': 1,\n",
    "            'num_workers': 1,\n",
    "            'test_starting_point': 15,\n",
    "            'num_total_output_frames':80,\n",
    "            'debug': False}\n",
    "\n",
    "    args_new = Namespace(**dd)\n",
    "    experiment = Experiment(args_new)\n",
    "    experiment.load_from_disk(test=True)\n",
    "    \n",
    "    output_frames, target_frames = get_test_predictions_pairs(experiment.model, belated, \n",
    "                                                              batch_images, \n",
    "                                                              args_new.test_starting_point-experiment.args.num_input_frames, \n",
    "                                                              args_new.num_total_output_frames)\n",
    "    return image_prepro(output_frames, experiment.normalizer), image_prepro(target_frames, experiment.normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_exp_name = {'ar_lstm_': 'LSTM',\n",
    "                 'convlstm': 'ConvLSTM',\n",
    "                 'predrnn_': 'PredRNN++',\n",
    "                 'resnet_b': 'ResNet',\n",
    "                 'resnet_d': 'ResNet Dil',\n",
    "                 'unet_bat': 'U-Net'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar_lstm_batch_16_samples_10_in_5_out_20_normal_lr_0.0001_dataset_original_16h_patience_5\n",
    "# convlstm_batch_8_samples_5_in_5_out_10_normal_lr_0.001_16h_c_belated\n",
    "# predrnn_batch_4_samples_5_in_5_out_20_normal_lr_0.0001_dataset_original_24h_patience_3_belated\n",
    "# resnet_batch_16_samples_5_in_5_out_10_normal_lr_0.001\n",
    "# unet_batch_16_samples_5_in_5_out_20_normal_lr_0.0001_dataset_original_16h_patience_7\n",
    "\n",
    "exp_to_plot = [\n",
    " 'ar_lstm_batch_16_samples_10_in_5_out_20_normal_lr_0.0001_dataset_original_16h_patience_5',\n",
    " 'convlstm_batch_8_samples_5_in_5_out_10_normal_lr_0.001_16h_c_belated',\n",
    " 'predrnn_batch_4_samples_5_in_5_out_20_normal_lr_0.0001_dataset_original_24h_patience_3_belated',\n",
    " 'resnet_batch_16_samples_5_in_5_out_10_normal_lr_0.001',\n",
    "'resnet_dilated_batch_16_samples_5_in_5_out_10_normal_lr_0.001_dataset_original_16h_patience_7',\n",
    " 'unet_batch_16_samples_5_in_5_out_20_normal_lr_0.0001_dataset_original_16h_patience_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_model_comparison(test_set):\n",
    "    batch_images = batch_images_all[test_set]\n",
    "    frames = [9, 19, 29, 39, 59, 79]\n",
    "    fig, ax = plt.subplots(len(exp_to_plot)+1, len(frames), figsize = (13.5, 17))\n",
    "\n",
    "    fontsize = 16\n",
    "\n",
    "    for i, exp in enumerate(exp_to_plot):\n",
    "        output_frames, target_frames = get_experiment_predictions(exp, batch_images)\n",
    "#         print(output_frames.min(), output_frames.max())\n",
    "        i += 1\n",
    "        ax[i, 0].set_ylabel(real_exp_name[exp[:8]], rotation=45, fontsize=fontsize)\n",
    "        for t in range(len(frames)):\n",
    "            ax[i, t].imshow(output_frames[0, frames[t], :, :], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[i, t].yaxis.set_label_coords(-0.2,0.5)\n",
    "            ax[i, t].get_yaxis().set_ticks([])\n",
    "            ax[i, t].spines['top'].set_visible(False)\n",
    "            ax[i, t].spines['right'].set_visible(False)\n",
    "            ax[i, t].spines['bottom'].set_visible(False)\n",
    "            ax[i, t].spines['left'].set_visible(False)\n",
    "            ax[i, t].tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False)\n",
    "            \n",
    "    i = 0\n",
    "    t = 0\n",
    "    ax[i, t].set_ylabel('Ground truth', rotation=45, fontsize=fontsize, labelpad=100)\n",
    "    for t in range(len(frames)):\n",
    "        ax[i, t].imshow(target_frames[0, frames[t], :, :], cmap='gray', vmin=0 , vmax=1)\n",
    "        ax[i, t].yaxis.set_label_coords(-0.2,0.5)\n",
    "        ax[i, t].get_yaxis().set_ticks([])\n",
    "        ax[i, t].spines['top'].set_visible(False)\n",
    "        ax[i, t].spines['right'].set_visible(False)\n",
    "        ax[i, t].spines['bottom'].set_visible(False)\n",
    "        ax[i, t].spines['left'].set_visible(False)\n",
    "        ax[i, t].tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False)\n",
    "        ax[i, t].set_title('t = ' + str(frames[t]+1), fontsize=fontsize)\n",
    "\n",
    "    fig.suptitle(test_set, fontsize=fontsize*1.5) # or plt.suptitle('Main title')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.01, top=0.90, wspace=0.03)\n",
    "    plt.savefig('qualitative/Best_Model_Comparison/Evaluate_%s.png'% test_set, format='png')\n",
    "    plt.savefig('qualitative/Best_Model_Comparison/PDF_Evaluate_%s.pdf'% test_set, format='pdf')\n",
    "#     plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_1\n",
      "Test_2\n",
      "Test_3\n",
      "Lines_1\n",
      "Lines_2\n",
      "Lines_3\n",
      "Double_Drop_1\n",
      "Double_Drop_2\n",
      "Double_Drop_3\n",
      "Illumination_135_1\n",
      "Illumination_135_2\n",
      "Illumination_135_3\n",
      "Shallow_Depth_1\n",
      "Shallow_Depth_2\n",
      "Shallow_Depth_3\n",
      "Smaller_Tub_1\n",
      "Smaller_Tub_2\n",
      "Smaller_Tub_3\n",
      "Bigger_Tub_1\n",
      "Bigger_Tub_2\n",
      "Bigger_Tub_3\n",
      "Fixed_Tub_1\n",
      "Fixed_Tub_2\n",
      "Fixed_Tub_3\n"
     ]
    }
   ],
   "source": [
    "for test_set in batch_images_all.keys():\n",
    "    print(test_set)\n",
    "    plot_model_comparison(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_frames, target_frames = get_experiment_predictions(exp, batch_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
