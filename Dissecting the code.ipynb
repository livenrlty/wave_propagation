{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import measure #supports video also\n",
    "from torchvision.transforms import functional as FF\n",
    "import pickle\n",
    "import scipy.ndimage as ndimage\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imagehash\n",
    "import math as m\n",
    "from scipy.spatial import distance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving and loading of figures, network state and other .pickle objects\n",
    "\"\"\"\n",
    "def save_network(obj, filename):\n",
    "    network_dict = obj.cpu().state_dict()\n",
    "    ## Add if torch.cuda.is_available():\n",
    "    obj.to(device)\n",
    "    save(obj=network_dict, filename=filename)\n",
    "\n",
    "def save(obj, filename):\n",
    "    filename += \".pickle\" if \".pickle\" not in filename else \"\"\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(filename):\n",
    "    filename += \".pickle\" if \".pickle\" not in filename else \"\"\n",
    "    with open(filename, 'rb') as handle:\n",
    "        return pickle.load(handle)\n",
    "\n",
    "def figure_save(destination, obj=None):\n",
    "    plt.savefig(destination)\n",
    "    plt.savefig(destination + \".svg\", format=\"svg\")\n",
    "    save(obj, destination) if obj else None\n",
    "    \n",
    "def make_folder_results(folder_name):\n",
    "    if os.path.isdir(folder_name):\n",
    "        imgs = os.listdir(folder_name)\n",
    "        for img in imgs:\n",
    "            os.remove(folder_name + \"/\" + img)\n",
    "    else:\n",
    "        os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, smoothen=False, return_np=False, obj=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    if smoothen:\n",
    "        inp = ndimage.gaussian_filter(inp, sigma=(.5, .5, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    if obj is not None:\n",
    "        obj.imshow(inp)\n",
    "        obj.axis(\"off\")\n",
    "        if title is not None:\n",
    "            obj.set_title(title)\n",
    "    else:\n",
    "        plt.imshow(inp)\n",
    "        plt.axis(\"off\")\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "    if return_np:\n",
    "        return inp\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transformVar = {\"Test\": transforms.Compose([\n",
    "    transforms.Resize(128),    #Already 184 x 184\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize\n",
    "]),\n",
    "    \"Train\": transforms.Compose([\n",
    "    transforms.Resize(128),  # Already 184 x 184\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_Data(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a data-loader.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_directory, transform=None, check_bad_data=True, channels=3):\n",
    "        if isinstance(root_directory, str):\n",
    "            self.root_dir = root_directory\n",
    "            self.classes = listdir(root_directory)\n",
    "            self.All_Imagesets = []\n",
    "            for cla in self.classes:\n",
    "                im_list = sorted(listdir(root_directory + cla))\n",
    "                if not check_bad_data:\n",
    "                    self.All_Imagesets.append((im_list, cla))\n",
    "                else:\n",
    "                    Good = True\n",
    "                    for im in im_list:\n",
    "                        Good = Good and self.filter_bad_data(root_directory + cla + \"/\" + im)\n",
    "                    if Good:\n",
    "                        self.All_Imagesets.append((im_list, cla))\n",
    "\n",
    "        elif isinstance(root_directory, list):\n",
    "            self.root_dir = root_directory[0]\n",
    "            self.classes = root_directory[1]\n",
    "            self.All_Imagesets = root_directory[2]\n",
    "\n",
    "        self.transform = transform\n",
    "        self.channels=channels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.All_Imagesets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print('Get item')\n",
    "        img_path = self.All_Imagesets[idx][1]\n",
    "        im_list = sorted(listdir(self.root_dir + img_path))\n",
    "\n",
    "        Concat_Img = self.concatenate_data(img_path, im_list)\n",
    "\n",
    "        sample = {\"image\": Concat_Img,\n",
    "                  \"target\": torch.LongTensor([self.classes.index(str(img_path))])}\n",
    "        return sample\n",
    "\n",
    "    def filter_bad_data(self, img_path):\n",
    "        img = Image.open(img_path)\n",
    "        return False if np.shape(img)[-1] != 3 else True\n",
    "\n",
    "    def concatenate_data(self, img_path, im_list):\n",
    "        \"\"\"\n",
    "        Concatenated image tensor with all images having the same random transforms applied\n",
    "        \"\"\"\n",
    "        for i, image in enumerate(im_list):\n",
    "            if self.channels == 1:\n",
    "                img = Image.open(self.root_dir + img_path + \"/\" + image).convert('L')\n",
    "            elif self.channels == 3:\n",
    "                img = Image.open(self.root_dir + img_path + \"/\" + image)\n",
    "            if i == 0:\n",
    "                if self.transform:\n",
    "                    for t in self.transform.transforms:\n",
    "                        if \"RandomResizedCrop\" in str(t):\n",
    "                            ii, j, h, w = t.get_params(img, t.scale, t.ratio)\n",
    "                            img = FF.resized_crop(img, ii, j, h, w, t.size, t.interpolation)\n",
    "                        elif \"RandomHorizontalFlip\" in str(t):\n",
    "                            Horizontal_Flip = random.choice([True, False])\n",
    "                            if Horizontal_Flip:\n",
    "                                img = FF.hflip(img)\n",
    "                        elif \"RandomVerticalFlip\" in str(t):\n",
    "                            Vertical_Flip = random.choice([True, False])\n",
    "                            if Vertical_Flip:\n",
    "                                img = FF.vflip(img)\n",
    "                        else:\n",
    "                            img = t(img)\n",
    "                Concat_Img = img\n",
    "            else:\n",
    "                if self.transform:\n",
    "                    for t in self.transform.transforms:\n",
    "                        if \"RandomResizedCrop\" in str(t):\n",
    "                            img = FF.resized_crop(img, ii, j, h, w, t.size, t.interpolation)\n",
    "                        elif \"RandomHorizontalFlip\" in str(t):\n",
    "                            if Horizontal_Flip:\n",
    "                                img = FF.hflip(img)\n",
    "                        elif \"RandomVerticalFlip\" in str(t):\n",
    "                            if Vertical_Flip:\n",
    "                                img = FF.vflip(img)\n",
    "                        else:\n",
    "                            img = t(img)\n",
    "                Concat_Img = torch.cat((Concat_Img, img), dim=0)\n",
    "        return Concat_Img\n",
    "\n",
    "\n",
    "def Create_Training_Testing_Datasets(root_directory, transform=None, test_fraction=0., validation_fraction=0., check_bad_data=True, channels=3):\n",
    "    \"\"\"\n",
    "    Splits data into fractional parts (data does not overlap!!) and creates data-loaders for each fraction.\n",
    "    :param root_directory: Directory of data\n",
    "    :param transform: transforms to apply for each data set. Must contain \"Train\" and \"Test\" dict\n",
    "    :param test_fraction: Fraction of data to go to test-set\n",
    "    :param validation_fraction: Fraction of data to go to validation-set\n",
    "    :param check_bad_data: Option to evaluate and filter out corrupted data/images\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def filter_bad_data(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        return False if np.shape(img)[-1] != 3 else True\n",
    "\n",
    "    print('Create datasets')\n",
    "    if (test_fraction > 0) or (validation_fraction > 0):\n",
    "        classes = listdir(root_directory)\n",
    "        All_Imagesets = []\n",
    "        for cla in classes:\n",
    "            im_list = sorted(listdir(root_directory + cla))\n",
    "            if not check_bad_data:\n",
    "                All_Imagesets.append((im_list, cla))\n",
    "            else:\n",
    "                Good = True\n",
    "                for im in im_list:\n",
    "                    Good = Good and filter_bad_data(root_directory + cla + \"/\" + im)\n",
    "                if Good:\n",
    "                    All_Imagesets.append((im_list, cla))\n",
    "\n",
    "        full_size = len(All_Imagesets)\n",
    "        if test_fraction > 0:\n",
    "            test = random.sample(All_Imagesets, int(full_size * test_fraction)) # All images i list of t0s\n",
    "            for item in test:\n",
    "                All_Imagesets.remove(item)\n",
    "\n",
    "            Send = [root_directory, classes, test]\n",
    "            Test = Get_Data(Send, transform[\"Test\"], channels=channels)\n",
    "#             yield Test\n",
    "\n",
    "        if validation_fraction > 0:\n",
    "            validate = random.sample(All_Imagesets, int(full_size * validation_fraction))  # All images i list of t0s\n",
    "            for item in validate:\n",
    "                All_Imagesets.remove(item)\n",
    "\n",
    "            Send = [root_directory, classes, validate]\n",
    "            Validate = Get_Data(Send, transform[\"Test\"], channels=channels)\n",
    "#             yield Validate\n",
    "\n",
    "        Send = [root_directory, classes, All_Imagesets]\n",
    "        Train = Get_Data(Send, transform[\"Train\"], channels=channels)\n",
    "#         yield Train\n",
    "        return Test, Validate, Train\n",
    "    else:\n",
    "        Data = Get_Data(root_directory, transform, check_bad_data=check_bad_data, channels=channels)\n",
    "        return Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: Video_Data/.DS_Store: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf Results/\n",
    "!rm Video_Data/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create datasets\n"
     ]
    }
   ],
   "source": [
    "nr_net = 0 \n",
    "\n",
    "version = nr_net + 10\n",
    "input_frames = 5\n",
    "output_frames = 10\n",
    "Type_Network = \"7_kernel_3LSTM\"\n",
    "DataGroup = \"LSTM\"\n",
    "\n",
    "\n",
    "# Little trick to adjust path files for compatibility (I have a backup of the Main.py in case it doesn't work)\n",
    "# stef_path = \"/media/sg6513/DATADRIVE2/MSc/Wavebox/\"\n",
    "# if os.path.isfile(stef_path + \"stefpc.txt\"):\n",
    "#     if not os.path.isdir(stef_path + \"Results\"):\n",
    "#         os.mkdir(stef_path + \"Results\")\n",
    "#     maindir1 = stef_path + \"Results/Simulation_Result_\" + Type_Network + \"_v%03d/\" % version\n",
    "#     maindir2 = stef_path\n",
    "#     version += 200\n",
    "# else:\n",
    "if not os.path.isdir(\"./Results\"):\n",
    "    os.mkdir(\"./Results\")\n",
    "# maindir1 = \"/mnt/Linux-HDD/Discrete_Data-sharing_LSTMs/Results/Simulation_Result_\"\\\n",
    "maindir1 = \"./Results/Simulation_Result_\"\\\n",
    "           + Type_Network + \"_v%03d/\" % version\n",
    "\n",
    "if not os.path.isdir(maindir1):\n",
    "    make_folder_results(maindir1)\n",
    "\n",
    "# Data\n",
    "if os.path.isfile(maindir1 + \"All_Data_\" + DataGroup + \"_v%03d.pickle\" % version):\n",
    "    My_Data = load(maindir1 + \"All_Data_\" + DataGroup + \"_v%03d\" % version)\n",
    "    My_Train = My_Data[\"Training data\"]\n",
    "    My_Validate = My_Data[\"Validation data\"]\n",
    "    My_Test = My_Data[\"Testing data\"]\n",
    "else:\n",
    "    My_Test, My_Validate, My_Train = Create_Training_Testing_Datasets(\n",
    "         \"./Video_Data/\", transformVar, test_fraction=0.15, validation_fraction=0.15, check_bad_data=False, channels=channels)\n",
    "    My_Data = {\"Training data\": My_Train, \"Validation data\": My_Validate, \"Testing data\": My_Test}\n",
    "    save(My_Data, maindir1 + \"All_Data_\" + DataGroup + \"_v%03d\" % version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = DataLoader(My_Train, batch_size=16, shuffle=True, num_workers=12)\n",
    "Validate_Data = DataLoader(My_Validate, batch_size=16, shuffle=True, num_workers=12)\n",
    "Test_Data = DataLoader(My_Test, batch_size=16, shuffle=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = My_Train[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# img = imgs[3*i:3*(i+1),:,:]\n",
    "# imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 128])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = My_Train.root_dir\n",
    "img_path = My_Train.All_Imagesets[0]\n",
    "im_list = sorted(listdir(root_dir + img_path[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Analyser():\n",
    "    \"\"\"\n",
    "    Saves network data for later analasys. Epochwise loss, Batchwise loss, Accuracy (not currently in use) and\n",
    "    Validation loss\n",
    "    \"\"\"\n",
    "    def __init__(self, maindir1):\n",
    "        self.epoch_loss = []\n",
    "        self.epoch_nr = []\n",
    "        self.batch_loss = []\n",
    "        self.batch_nr = []\n",
    "        self.accuracy = []\n",
    "        self.epoch_acc = []\n",
    "        self.validation_loss = []\n",
    "        self.validation_nr = []\n",
    "        self.maindir1 = maindir1\n",
    "\n",
    "    def save_loss(self, loss, epoch_increment=1):\n",
    "        \"\"\"\n",
    "        Creates two lists, one of losses and one of index of epoch\n",
    "        \"\"\"\n",
    "        self.epoch_loss.append(loss)\n",
    "        self.epoch_nr.append(self.epoch_nr[len(self.epoch_nr) - 1] + epoch_increment) if len(self.epoch_nr)\\\n",
    "            else self.epoch_nr.append(epoch_increment)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        fig = plt.figure().add_axes()\n",
    "        sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "        sns.set_context(\"talk\")\n",
    "        data = {}\n",
    "        data.update({\"Epoch\": self.epoch_nr, \"Loss\": self.epoch_loss})\n",
    "        sns.lineplot(x=\"Epoch\", y=\"Loss\",\n",
    "                     data=pd.DataFrame.from_dict(data), ax=fig)\n",
    "        figure_save(self.self.maindir1 + \"Epoch_Loss\" + Type_Network + \"_Project_v%03d\" % version, obj=fig)\n",
    "        plt.show()\n",
    "\n",
    "    def save_loss_batchwise(self, loss, batch_increment=1):\n",
    "        \"\"\"\n",
    "        Creates two lists, one of losses and one of index of batch\n",
    "        \"\"\"\n",
    "        self.batch_loss.append(loss)\n",
    "        self.batch_nr.append(self.batch_nr[len(self.batch_nr) - 1] + batch_increment) if len(self.batch_nr)\\\n",
    "            else self.batch_nr.append(batch_increment)\n",
    "\n",
    "    def plot_loss_batchwise(self):\n",
    "        fig = plt.figure().add_axes()\n",
    "        sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "        sns.set_context(\"talk\")\n",
    "        data = {}\n",
    "        data.update({\"Batch\": self.batch_nr, \"Loss\": self.batch_loss})\n",
    "        sns.lineplot(x=\"Batch\", y=\"Loss\",\n",
    "                     data=pd.DataFrame.from_dict(data), ax=fig)\n",
    "        figure_save(self.self.maindir1 + \"Batch_Loss\" + Type_Network + \"_Project_v%03d\" % version, obj=fig)\n",
    "        plt.show()\n",
    "\n",
    "    def save_accuracy(self, accuracy, epoch_increment=1):\n",
    "        \"\"\"\n",
    "        Creates two lists, one of accuracy and one of index of the accuracy (batchwise or epochwise)\n",
    "        NOT IN USE\n",
    "        \"\"\"\n",
    "        self.accuracy.append(accuracy)\n",
    "        self.epoch_acc.append(self.epoch_acc[len(self.epoch_acc) - 1] + epoch_increment) if len(self.epoch_acc)\\\n",
    "            else self.epoch_acc.append(epoch_increment)\n",
    "\n",
    "    def plot_accuracy(self):\n",
    "        fig = plt.figure().add_axes()\n",
    "        sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "        sns.set_context(\"talk\")\n",
    "        data = {}\n",
    "        data.update({\"Epoch\": self.epoch_acc, \"Accuracy\": self.accuracy})\n",
    "        sns.lineplot(x=\"Epoch\", y=\"Accuracy\",\n",
    "                     data=pd.DataFrame.from_dict(data), ax=fig)\n",
    "        figure_save(self.self.maindir1 + \"Accuracy\" + Type_Network + \"_Project_v%03d\" % version, obj=fig)\n",
    "        plt.show()\n",
    "\n",
    "    def save_validation_loss(self, loss, epoch_increment=1):\n",
    "        \"\"\"\n",
    "        Creates two lists, one of validation losses and one of index of epoch\n",
    "        \"\"\"\n",
    "        self.validation_loss.append(loss)\n",
    "        self.validation_nr.append(self.validation_nr[len(self.validation_nr) - 1] + epoch_increment) if \\\n",
    "            len(self.validation_nr) else self.validation_nr.append(epoch_increment)\n",
    "\n",
    "    def plot_validation_loss(self):\n",
    "        \"\"\"\n",
    "        Plots validation and epoch loss next to each other\n",
    "        \"\"\"\n",
    "        hue = []\n",
    "        loss = []\n",
    "        nr = []\n",
    "        for i, element in enumerate(self.epoch_loss):\n",
    "            loss.append(element)\n",
    "            nr.append(self.epoch_nr[i])\n",
    "            hue.append(\"Training Loss\")\n",
    "        for i, element in enumerate(self.validation_loss):\n",
    "            loss.append(element)\n",
    "            nr.append(self.validation_nr[i])\n",
    "            hue.append(\"Validation Loss\")\n",
    "        fig = plt.figure().add_axes()\n",
    "        sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "        sns.set_context(\"talk\")\n",
    "        data = {}\n",
    "        data.update({\"Epoch\": nr, \"Loss\": loss, \"hue\": hue})\n",
    "        sns.lineplot(x=\"Epoch\", y=\"Loss\", hue=\"hue\",\n",
    "                     data=pd.DataFrame.from_dict(data), ax=fig)\n",
    "        figure_save(self.maindir1 + \"Validation_Loss\" + Type_Network + \"_Project_v%03d\" % version, obj=fig)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser\n",
    "if os.path.isfile(maindir1 + Type_Network + \"_Analyser_v%03d.pickle\" % version):\n",
    "    Analyser = load(maindir1 + Type_Network + \"_Analyser_v%03d\" % version)\n",
    "else:\n",
    "    Analyser = Data_Analyser(maindir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network (nn.Module):\n",
    "    \"\"\"\n",
    "    The network structure\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(Network, self).__init__()\n",
    "        self.channels=channels\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(5*channels, 60, kernel_size=7, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=60),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(60, 120, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(120, 240, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=240),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(240, 480, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=480),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        self.encoder_linear = nn.Sequential(\n",
    "            nn.Linear(30720, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.decoder_linear = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1000, 30720)\n",
    "        )\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(480, 240, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=240),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(240, 120, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(120, 60, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=60),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.ConvTranspose2d(60, channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "        self.LSTM_0 = nn.LSTMCell(input_size=1000, hidden_size=1000, bias=True)\n",
    "\n",
    "        self.LSTM = nn.LSTMCell(input_size=1000, hidden_size=1000, bias=True)\n",
    "\n",
    "        self.LSTM_new_input = nn.LSTMCell(input_size=1000, hidden_size=1000, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, mode=\"input\", training=False): #\"input\", \"new_input\", \"internal\"\n",
    "        x.requires_grad_(training)\n",
    "        with torch.set_grad_enabled(training):\n",
    "            if \"input\" in mode:\n",
    "                x = self.encoder_conv(x)\n",
    "                self.org_size = x.size()\n",
    "                x = x.view(-1, 30720)\n",
    "                x = self.encoder_linear(x)\n",
    "                if mode == \"input\":\n",
    "                    self.h0, self.c0 = self.LSTM_0(x, (self.h0, self.c0))\n",
    "                elif mode == \"new_input\":\n",
    "                    self.h0, self.c0 = self.LSTM_new_input(x, (self.h0, self.c0))\n",
    "            elif mode == \"internal\":\n",
    "                self.h0, self.c0 = self.LSTM(self.h0, (self.h0, self.c0))\n",
    "            x = self.h0.clone()\n",
    "            x = self.decoder_linear(x)\n",
    "            x = x.view(self.org_size)\n",
    "            x = self.decoder_conv(x)\n",
    "            return x\n",
    "\n",
    "    def reset_hidden(self, batch_size, training=False):\n",
    "        self.h0 = torch.zeros((batch_size, 1000), requires_grad=training).to(device) #Requires grad replaces Variable\n",
    "        self.c0 = torch.zeros((batch_size, 1000), requires_grad=training).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "if os.path.isfile(maindir1 + Type_Network + \"_Project_v%03d.pt\" % version):\n",
    "    model = torch.load(maindir1 + Type_Network + \"_Project_v%03d.pt\" % version)\n",
    "else:\n",
    "    model = Network(channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Scorekeeper():\n",
    "    \"\"\"\n",
    "    Calculates and keeps track of testing results\n",
    "    SSIM/pHash/RMSE etc.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Scorekeeper, self).__init__()\n",
    "\n",
    "        self.intermitted = []\n",
    "        self.frame = []\n",
    "        self.hue = []\n",
    "\n",
    "        self.pHash_val = []\n",
    "        self.pHash_frame = []\n",
    "        self.pHash_hue = []\n",
    "\n",
    "        self.pHash2_val = []\n",
    "        self.pHash2_frame = []\n",
    "        self.pHash2_hue = []\n",
    "\n",
    "        self.SSIM_val = []\n",
    "        self.SSIM_frame = []\n",
    "        self.SSIM_hue = []\n",
    "\n",
    "        self.MSE_val = []\n",
    "        self.MSE_frame = []\n",
    "        self.MSE_hue = []\n",
    "\n",
    "        self.own = False\n",
    "        self.phash = False\n",
    "        self.SSIM = False\n",
    "        self.MSE = False\n",
    "\n",
    "    def add(self, predicted, target, frame_nr, *args):\n",
    "        predicted = self.normalize(predicted)\n",
    "        target = self.normalize(target)\n",
    "\n",
    "        if \"Own\"in args:\n",
    "            spatial_score, scale_score = self.score(predicted, target)\n",
    "            self.intermitted.append(spatial_score)\n",
    "            self.frame.append(frame_nr)\n",
    "            self.hue.append(\"Spatial\")\n",
    "            self.intermitted.append(scale_score)\n",
    "            self.frame.append(frame_nr)\n",
    "            self.hue.append(\"Scaling\")\n",
    "            self.own = True\n",
    "\n",
    "        if \"SSIM\" in args:\n",
    "            ssim_score = self.ssim(predicted, target)\n",
    "            self.SSIM_val.append(ssim_score)\n",
    "            self.SSIM_frame.append(frame_nr)\n",
    "            self.SSIM_hue.append(\"SSIM\")\n",
    "            self.SSIM = True\n",
    "\n",
    "        if \"RMSE\" in args:\n",
    "            self.MSE_val.append(np.sqrt(measure.compare_mse(predicted, target)))\n",
    "            self.MSE_frame.append(frame_nr)\n",
    "            self.MSE_hue.append(\"RMSE\")\n",
    "            self.MSE = True\n",
    "\n",
    "        if \"pHash\" in args:\n",
    "            hamming = self.pHash(predicted, target, \"hamming\")\n",
    "            self.pHash_val.append(hamming)\n",
    "            self.pHash_frame.append(frame_nr)\n",
    "            self.pHash_hue.append(\"pHash\")\n",
    "            self.phash = True\n",
    "\n",
    "        if \"pHash\" in args:\n",
    "            hamming = self.pHash(predicted, target, \"jaccard\")\n",
    "            self.pHash2_val.append(hamming)\n",
    "            self.pHash2_frame.append(frame_nr)\n",
    "            self.pHash2_hue.append(\"pHash\")\n",
    "            self.phash2 = True\n",
    "\n",
    "    def hamming2(self, s1, s2):\n",
    "        \"\"\"Calculate the Hamming distance between two bit strings\"\"\"\n",
    "        assert len(s1) == len(s2)\n",
    "        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "    def pHash(self, predicted, target, *args):\n",
    "        predicted = predicted * 255\n",
    "        target = target * 255\n",
    "        predicted = Image.fromarray(predicted.astype(\"uint8\"))\n",
    "        target = Image.fromarray(target.astype(\"uint8\"))\n",
    "        hash1 = hex_str2bool(str(imagehash.phash(predicted, hash_size=16)))\n",
    "        hash2 = hex_str2bool(str(imagehash.phash(target, hash_size=16)))\n",
    "        if \"hamming\" in args:\n",
    "            return self.hamming2(hash1, hash2)\n",
    "        elif \"jaccard\" in args:\n",
    "            return distance.jaccard(hash1, hash2)\n",
    "        else:\n",
    "            return None\n",
    "        # Out of 260\n",
    "\n",
    "    def ssim(self, predicted, target):\n",
    "        return measure.compare_ssim(predicted, target, multichannel=True, gaussian_weights=True)\n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        return np.clip(image, 0, 1)\n",
    "\n",
    "    def score(self, predicted, target):\n",
    "        predicted_mean = np.mean(predicted, axis=(0, 1))\n",
    "        target_mean = np.mean(target, axis=(0, 1))\n",
    "        pred_relative = np.abs(predicted - predicted_mean)\n",
    "        target_relative = np.abs(target - target_mean)\n",
    "\n",
    "        relative_diff = np.mean(np.abs(pred_relative - target_relative)) \\\n",
    "                        / (np.sum(target_relative) / np.prod(np.shape(target)))\n",
    "\n",
    "        absolute_diff = np.mean(np.abs(predicted - target)) / (np.sum(target) / np.prod(np.shape(target)))\n",
    "\n",
    "        return relative_diff, absolute_diff\n",
    "\n",
    "    def plot(self):\n",
    "        if self.own:\n",
    "            all_data = {}\n",
    "            all_data.update({\"Time-steps Ahead\": self.frame, \"Difference\": self.intermitted, \"Scoring Type\": self.hue})\n",
    "            fig = plt.figure().add_axes()\n",
    "            sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "            sns.lineplot(x=\"Time-steps Ahead\", y=\"Difference\", hue=\"Scoring Type\",\n",
    "                         data=pd.DataFrame.from_dict(all_data), ax=fig)\n",
    "            figure_save(maindir1 + \"Scoring_Quality\", obj=fig)\n",
    "            plt.show()\n",
    "\n",
    "        if self.SSIM:\n",
    "            all_data = {}\n",
    "            all_data.update({\"Time-steps Ahead\": self.SSIM_frame, \"Similarity\": self.SSIM_val,\n",
    "                                  \"Scoring Type\": self.SSIM_hue})\n",
    "            fig = plt.figure().add_axes()\n",
    "            sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "            sns.lineplot(x=\"Time-steps Ahead\", y=\"Similarity\", hue=\"Scoring Type\",\n",
    "                         data=pd.DataFrame.from_dict(all_data), ax=fig)\n",
    "            plt.ylim(0, 1)\n",
    "            figure_save(maindir1 + \"SSIM_Quality\", obj=fig)\n",
    "            plt.show()\n",
    "\n",
    "        if self.MSE:\n",
    "            all_data = {}\n",
    "            all_data.update({\"Time-steps Ahead\": self.MSE_frame, \"Root Mean Square Error (L2 residual)\": self.MSE_val,\n",
    "                                 \"Scoring Type\": self.MSE_hue})\n",
    "            fig = plt.figure().add_axes()\n",
    "            sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "            sns.lineplot(x=\"Time-steps Ahead\", y=\"Root Mean Square Error (L2 residual)\", hue=\"Scoring Type\",\n",
    "                         data=pd.DataFrame.from_dict(all_data), ax=fig)\n",
    "            figure_save(maindir1 + \"RMSE_Quality\", obj=fig)\n",
    "            plt.show()\n",
    "\n",
    "        if self.phash:\n",
    "            all_data = {}\n",
    "            all_data.update({\"Time-steps Ahead\": self.pHash_frame, \"Hamming Distance\": self.pHash_val,\n",
    "                                   \"Scoring Type\": self.pHash_hue})\n",
    "            fig = plt.figure().add_axes()\n",
    "            sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "            sns.lineplot(x=\"Time-steps Ahead\", y=\"Hamming Distance\", hue=\"Scoring Type\",\n",
    "                         data=pd.DataFrame.from_dict(all_data), ax=fig)\n",
    "            figure_save(maindir1 + \"Scoring_Spatial_Hamming\", obj=fig)\n",
    "            plt.show()\n",
    "\n",
    "        if self.phash2:\n",
    "            all_data = {}\n",
    "            all_data.update({\"Time-steps Ahead\": self.pHash2_frame, \"Jaccard Distance\": self.pHash2_val,\n",
    "                                   \"Scoring Type\": self.pHash2_hue})\n",
    "            fig = plt.figure().add_axes()\n",
    "            sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, and ticks\n",
    "            sns.lineplot(x=\"Time-steps Ahead\", y=\"Jaccard Distance\", hue=\"Scoring Type\",\n",
    "                         data=pd.DataFrame.from_dict(all_data), ax=fig)\n",
    "            figure_save(maindir1 + \"Scoring_Spatial_Jaccard\", obj=fig)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer created\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate scheduler w. optimizer\n",
    "if os.path.isfile(maindir1 + Type_Network + \"_lrScheduler_v%03d.pickle\" % version):\n",
    "    scheduler_dict = load(maindir1 + Type_Network + \"_lrScheduler_v%03d\" % version)\n",
    "    lrschedule = scheduler_dict[\"Type\"]\n",
    "    exp_lr_scheduler = scheduler_dict[\"Scheduler\"]\n",
    "else:\n",
    "    # Optimizer\n",
    "    optimizer_algorithm = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "    # Add learning rate schedulers\n",
    "    # Decay LR by a factor of gamma every step_size epochs\n",
    "    lrschedule = 'plateau'\n",
    "    if lrschedule == 'step':\n",
    "        gamma = 0.5\n",
    "        step_size = 40\n",
    "        exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_algorithm, step_size=step_size, gamma=gamma)\n",
    "    elif lrschedule == 'plateau':\n",
    "        # Reduce learning rate when a metric has stopped improving\n",
    "        exp_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_algorithm, mode='min', factor=0.1, patience=7)\n",
    "        optimizer_algorithm = []\n",
    "print('Optimizer created')\n",
    "\n",
    "model.to(device)\n",
    "score_keeper = Scorekeeper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(epoch, DataLoader, Validate, plot=True, channels=3):\n",
    "    \"\"\"\n",
    "    Training of the network\n",
    "    :param epoch: Which epoch are you on\n",
    "    :param DataLoader: Training data\n",
    "    :param Validate: Validation data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ### add grayscayle or rgb flag to gain speed\n",
    "    def initial_input(training, channels):\n",
    "        Data = ImageSeries[:, (t0 + n) * channels:(t0 + n + input_frames) * channels, :, :].to(device)\n",
    "        output = model(Data, training=training)\n",
    "        target = ImageSeries[:, (t0 + n + input_frames) * channels:(t0 + n + input_frames + 1) * channels, :, :].to(device)\n",
    "        return output, target\n",
    "\n",
    "    def new_input(output, target, training, channels):\n",
    "        output = torch.cat((output, model(\n",
    "            output[:, -input_frames * channels:, :, :].clone(), mode=\"new_input\", training=training)\n",
    "                            ), dim=1)\n",
    "        target = torch.cat(\n",
    "            (target, ImageSeries[:, (t0 + n + input_frames) * channels:(t0 + n + input_frames + 1) * channels, :, :].to(device)), dim=1\n",
    "        )\n",
    "        return output, target\n",
    "\n",
    "    def consequent_propagation(output, target, training, channels):\n",
    "        output = torch.cat((output, model(torch.Tensor([0]), mode=\"internal\", training=training)), dim=1)\n",
    "        target = torch.cat(\n",
    "            (target, ImageSeries[:, (t0 + n + input_frames) * channels:(t0 + n + input_frames + 1) * channels, :, :].to(device)), dim=1\n",
    "        )\n",
    "        return output, target\n",
    "\n",
    "    def plot_predictions():\n",
    "        if (i == 0) & (batch_num == 0):\n",
    "            predicted = output[i, -3:, :, :].cpu().detach()\n",
    "            des_target = target[i, -3:, :, :].cpu().detach()\n",
    "            fig = plt.figure()\n",
    "            pred = fig.add_subplot(1, 2, 1)\n",
    "            imshow(predicted, title=\"Predicted smoothened %02d\" % n, smoothen=True, obj=pred)\n",
    "            tar = fig.add_subplot(1, 2, 2)\n",
    "            imshow(des_target, title=\"Target %02d\" % n, obj=tar)\n",
    "            plt.show()\n",
    "\n",
    "    print('Training Epoch: %d' % epoch)\n",
    "    model.train()           # initialises training stage/functions\n",
    "    mean_loss = 0\n",
    "    print('Ready to load batches')\n",
    "    start_batch = time.time()\n",
    "    for batch_num, batch in enumerate(DataLoader):\n",
    "        batch_time = time.time() - start_batch\n",
    "        print('Batch: %d loaded in %.3f' %(batch_num, batch_time))\n",
    "        mean_batch_loss = 0\n",
    "        Starting_times = random.sample(range(100 - input_frames - (2 * output_frames) - 1), 10)\n",
    "        ImageSeries = batch[\"image\"]\n",
    "        for i, t0 in enumerate(Starting_times):\n",
    "            forward_start = time.time()\n",
    "            print('Starting t0: %d' % t0)\n",
    "            model.reset_hidden(batch_size=ImageSeries.size()[0], training=True)\n",
    "            exp_lr_scheduler.optimizer.zero_grad()\n",
    "            for n in range(2 * output_frames):\n",
    "                if n == 0:\n",
    "                    output, target = initial_input(training=True, channels=channels)\n",
    "                elif n == output_frames:\n",
    "                    output, target = new_input(output, target, training=True, channels=channels)\n",
    "                else:\n",
    "                    output, target = consequent_propagation(output, target, training=True, channels=channels)\n",
    "                if plot:\n",
    "                    plot_predictions()\n",
    "            loss = F.mse_loss(output, target)\n",
    "            forward_time = time.time() - forward_start\n",
    "            print('Forward time: %.3f' % forward_time)\n",
    "            loss.backward()\n",
    "            exp_lr_scheduler.optimizer.step()\n",
    "\n",
    "            mean_batch_loss += loss.item()\n",
    "            backward_time = time.time() - (forward_time + forward_start)\n",
    "            print('Backward time: %.3f' % backward_time)\n",
    "\n",
    "        Analyser.save_loss_batchwise(mean_batch_loss / (i + 1), 1)\n",
    "        mean_loss += loss.item()\n",
    "\n",
    "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(epoch, batch_num + 1,\n",
    "                   len(DataLoader), 100. * (batch_num + 1) / len(DataLoader), loss.item()))\n",
    "        start_batch = time.time()\n",
    "        \n",
    "    Analyser.save_loss(mean_loss / (batch_num + 1), 1)\n",
    "    #Analyser.plot_loss()\n",
    "    #Analyser.plot_loss_batchwise()\n",
    "    validation_loss = validate(Validate, plot=False)\n",
    "    Analyser.save_validation_loss(validation_loss, 1)\n",
    "    Analyser.plot_validation_loss()\n",
    "    print(\"Validation loss is\", validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = My_Train[0]['image'][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eef3bb320>"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "# for i, d in enumerate(My_Train):\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print(i, elapsed_time)\n",
    "#     if i > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "# for i, d in enumerate(Train_Data):\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print(i, elapsed_time)\n",
    "#     if i > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(My_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.625"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Test_Data.dataset)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 10\n",
      "Training Epoch: 1\n",
      "Ready to load batches\n",
      "Batch: 0 loaded in 16.582\n",
      "Starting t0: 57\n",
      "Forward time: 19.744\n",
      "Backward time: 9.419\n",
      "Starting t0: 52\n",
      "Forward time: 2.866\n",
      "Backward time: 8.140\n",
      "Starting t0: 14\n",
      "Forward time: 2.948\n",
      "Backward time: 7.714\n",
      "Starting t0: 66\n",
      "Forward time: 3.057\n",
      "Backward time: 8.049\n",
      "Starting t0: 29\n",
      "Forward time: 2.818\n",
      "Backward time: 7.846\n",
      "Starting t0: 10\n",
      "Forward time: 2.881\n",
      "Backward time: 7.633\n",
      "Starting t0: 21\n",
      "Forward time: 2.830\n",
      "Backward time: 7.834\n",
      "Starting t0: 51\n",
      "Forward time: 2.889\n",
      "Backward time: 8.020\n",
      "Starting t0: 4\n",
      "Forward time: 2.745\n",
      "Backward time: 7.378\n",
      "Starting t0: 2\n",
      "Forward time: 2.831\n",
      "Backward time: 7.393\n",
      "Train Epoch: 1 [1/144 (1%)]\tLoss: 0.500753\n",
      "Batch: 1 loaded in 0.002\n",
      "Starting t0: 47\n",
      "Forward time: 3.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-714-3fb692bf149d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlrschedule\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAnalyser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_Data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidate_Data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# perform scheduler step if Dependent on validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlrschedule\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plateau'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-709-bee3fd40562e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, DataLoader, Validate, plot, channels)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mforward_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforward_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Forward time: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mforward_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for _ in range(50 - len(Analyser.epoch_loss)):\n",
    "    print('Version %d' % version)\n",
    "    # for g in exp_lr_scheduler.optimizer.param_groups:\n",
    "    \"\"\"\n",
    "    Here we can access Analyser.validation_loss to make decisions\n",
    "    \"\"\"\n",
    "    # Learning rate scheduler\n",
    "    # perform scheduler step if independent from validation loss\n",
    "    if lrschedule == 'step':\n",
    "        exp_lr_scheduler.step()\n",
    "    train(len(Analyser.epoch_loss) + 1, Train_Data, Validate_Data, plot=False, channels=channels)\n",
    "    # perform scheduler step if Dependent on validation loss\n",
    "    if lrschedule == 'plateau':\n",
    "        exp_lr_scheduler.step(Analyser.validation_loss[-1])\n",
    "    save_network(model, maindir1 + Type_Network + \"_Project_v%03d\" % version)\n",
    "    torch.save(model, maindir1 + Type_Network + \"_Project_v%03d.pt\" % version)\n",
    "    save(Analyser, maindir1 + Type_Network + \"_Analyser_v%03d\" % version)\n",
    "    scheduler_dict = {\"Type\": lrschedule, \"Scheduler\": exp_lr_scheduler}\n",
    "    save(scheduler_dict, maindir1 + Type_Network + \"_lrScheduler_v%03d\" % version)\n",
    "test(Test_Data, plot=False)\n",
    "Analyser = []\n",
    "model =[]\n",
    "exp_lr_scheduler = []\n",
    "scheduler_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
