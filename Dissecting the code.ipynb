{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading datasets\n",
      "Creating analyser\n",
      "Experiment 10\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import measure #supports video also\n",
    "import pickle\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "import platform\n",
    "\n",
    "from utils.Network import Network\n",
    "from utils.Analyser import Analyser\n",
    "from utils.io import save_network, save, load, figure_save, make_folder_results, imshow\n",
    "from utils.format import hex_str2bool\n",
    "from utils.WaveDataset import Create_Datasets\n",
    "\n",
    "logging.basicConfig(format='%(message)s',level=logging.INFO)\n",
    "\n",
    "channels=1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transformVar = {\"Test\": transforms.Compose([\n",
    "    transforms.Resize(128),    #Already 184 x 184\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize\n",
    "]),\n",
    "    \"Train\": transforms.Compose([\n",
    "    transforms.Resize(128),  # Already 184 x 184\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "### COMMON FUNCTIONS TRAIN/VAL/TEST\n",
    "def initial_input(model, image_series, starting_point, num_input_frames, channels, device, training):\n",
    "    n = 0\n",
    "    input_frames = image_series[:, (starting_point + n) * channels:(starting_point + n + num_input_frames) * channels, :, :].to(device)\n",
    "    output_frames = model(input_frames, training=training)\n",
    "    index = starting_point + n + num_input_frames\n",
    "    target = image_series[:, index * channels:(index + 1) * channels, :, :].to(device)\n",
    "    return output_frames, target\n",
    "\n",
    "def new_input(model, image_series, starting_point, num_input_frames, num_output_frames, output_frames, target, channels, device, training):\n",
    "    output_frames = torch.cat((output_frames, model(output_frames[:, -num_input_frames * channels:, :, :].clone(), mode=\"new_input\", training=training)), dim=1)\n",
    "    index = starting_point + num_output_frames + num_input_frames\n",
    "    target = torch.cat((target, image_series[:, index * channels:(index + 1) * channels, :, :].to(device)), dim=1)\n",
    "    return output_frames, target\n",
    "\n",
    "def consequent_propagation(model, image_series, starting_point, n, output_frames, target, channels, device, training):\n",
    "    output_frames = torch.cat((output_frames, model(torch.Tensor([0]), mode=\"internal\", training=training)), dim=1)\n",
    "    index = starting_point + n + num_input_frames\n",
    "    target = torch.cat((target, image_series[:, index*channels:(index + 1) * channels, :, :].to(device)), dim=1)\n",
    "    return output_frames, target\n",
    "\n",
    "def plot_predictions():\n",
    "    if (i == 0) & (batch_num == 0):\n",
    "        predicted = output_frames[i, -channels:, :, :].cpu().detach()\n",
    "        des_target = target[i, -channels:, :, :].cpu().detach()\n",
    "        fig = plt.figure()\n",
    "        pred = fig.add_subplot(1, 2, 1)\n",
    "        imshow(predicted, title=\"Predicted smoothened %02d\" % n, smoothen=True, obj=pred)\n",
    "        tar = fig.add_subplot(1, 2, 2)\n",
    "        imshow(des_target, title=\"Target %02d\" % n, obj=tar)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def train_epoch(model, epoch, train_dataloader, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False,):\n",
    "    \"\"\"\n",
    "    Training of the network\n",
    "    :param train: Training data\n",
    "    :param val_dataloader: Validation data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    training = True\n",
    "    model.train()           # initialises training stage/functions\n",
    "    mean_loss = 0\n",
    "    logging.info('Training: Ready to load batches')\n",
    "    for batch_num, batch in enumerate(train_dataloader):\n",
    "        batch_start = time.time()\n",
    "        # logging.info('Batch: %d loaded in %.3f' %(batch_num, batch_time))\n",
    "        mean_batch_loss = 0\n",
    "        random_starting_points = random.sample(range(100 - num_input_frames - (2 * num_output_frames) - 1), 10)\n",
    "        image_series = batch[\"image\"]\n",
    "        for i, starting_point in enumerate(random_starting_points):\n",
    "            model.reset_hidden(batch_size=image_series.size()[0], training=True)\n",
    "            lr_scheduler.optimizer.zero_grad()\n",
    "            for n in range(2 * num_output_frames):\n",
    "                if n == 0:\n",
    "                    output_frames, target = initial_input(model, image_series, starting_point, num_input_frames, channels, device, training=training)\n",
    "                elif n == num_output_frames:\n",
    "                    output_frames, target = new_input(model, image_series, starting_point, num_input_frames, num_output_frames, output_frames, target, channels, device, training=training)\n",
    "                else:\n",
    "                    output_frames, target = consequent_propagation(model, image_series, starting_point, n, output_frames, target, channels, device, training=training)\n",
    "                if plot:\n",
    "                    plot_predictions()\n",
    "            loss = F.mse_loss(output_frames, target)\n",
    "            loss.backward()\n",
    "            lr_scheduler.optimizer.step()\n",
    "\n",
    "            mean_batch_loss += loss.item()\n",
    "        analyser.save_loss_batchwise(mean_batch_loss / (i + 1), batch_increment=1)\n",
    "        mean_loss += loss.item()\n",
    "\n",
    "        batch_time = time.time() - batch_start\n",
    "        logging.info(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime {:.2f}\".format(epoch, batch_num + 1,\n",
    "                   len(train_dataloader), 100. * (batch_num + 1) / len(train_dataloader), loss.item(), batch_time ) )        \n",
    "        \n",
    "    analyser.save_loss(mean_loss / (batch_num + 1), 1)\n",
    "    val_start = time.time()\n",
    "    validation_loss = validate(model, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False)\n",
    "    analyser.save_validation_loss(validation_loss, 1)\n",
    "    val_time = time.time() - val_start\n",
    "    logging.info('Validation loss: %.6f\\tTime: %.3f' % (validation_loss, val_time))\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False):\n",
    "    \"\"\"\n",
    "    Validation of network (same protocol as training)\n",
    "    :param val_dataloader: Data to test\n",
    "    :param plot: If to plot predictions\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    training = False\n",
    "    model.eval()\n",
    "    overall_loss = 0\n",
    "    for batch_num, batch in enumerate(val_dataloader):\n",
    "        random_starting_points = random.sample(range(100 - num_input_frames - (2 * num_output_frames) - 1), 10)\n",
    "        image_series = batch[\"image\"]\n",
    "        batch_loss = 0\n",
    "        for i, starting_point in enumerate(random_starting_points):\n",
    "            model.reset_hidden(batch_size=image_series.size()[0], training=False)\n",
    "            for n in range(2 * num_output_frames):\n",
    "                if n == 0:\n",
    "                    output_frames, target = initial_input(model, image_series, starting_point, num_input_frames, channels, device, training=training)\n",
    "                elif n == num_output_frames:\n",
    "                    output_frames, target = new_input(model, image_series, starting_point, num_input_frames, num_output_frames, output_frames, target, channels, device, training=training)\n",
    "                else:\n",
    "                    output_frames, target = consequent_propagation(model, image_series, starting_point, n, output_frames, target, channels, device, training=training)\n",
    "                if plot:\n",
    "                    plot_predictions()\n",
    "            batch_loss += F.mse_loss(output_frames, target).item()\n",
    "        overall_loss += batch_loss / (i + 1)\n",
    "    val_loss = overall_loss / (batch_num + 1)\n",
    "    return val_loss\n",
    "\n",
    "# get_ipython().system('rm -rf Results/')\n",
    "# get_ipython().system('rm Video_Data/.DS_Store')\n",
    "\n",
    "nr_net = 0 \n",
    "\n",
    "version = nr_net + 10\n",
    "num_input_frames = 5\n",
    "num_output_frames = 10\n",
    "network_type = \"7_kernel_3LSTM\"\n",
    "\n",
    "# Little trick to adjust path files for compatibility (I have a backup of the Main.py in case it doesn't work)\n",
    "# stef_path = \"/media/sg6513/DATADRIVE2/MSc/Wavebox/\"\n",
    "# if os.path.isfile(stef_path + \"stefpc.txt\"):\n",
    "#     if not os.path.isdir(stef_path + \"Results\"):\n",
    "#         os.mkdir(stef_path + \"Results\")\n",
    "#     results_dir = stef_path + \"Results/Simulation_Result_\" + network_type + \"_v%03d/\" % version\n",
    "#     maindir2 = stef_path\n",
    "#     version += 200\n",
    "# else:\n",
    "\n",
    "\n",
    "if 'Darwin' in platform.system():\n",
    "    data_dir = './'\n",
    "else:\n",
    "    data_dir = '/disk/scratch/s1680171/wave_propagation/'\n",
    "\n",
    "if not os.path.isdir(\"./Results\"):\n",
    "    os.mkdir(\"./Results\")\n",
    "results_dir = \"./Results/Simulation_Result_\" + network_type + \"_v%03d/\" % version\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    make_folder_results(results_dir)\n",
    "\n",
    "\n",
    "# Data\n",
    "filename_data = results_dir + \"all_data_\" + \"_v%03d.pickle\" % version\n",
    "if os.path.isfile(filename_data):\n",
    "    logging.info('Loading datasets')\n",
    "    all_data = load(filename_data)\n",
    "    train_dataset = all_data[\"Training data\"]\n",
    "    val_dataset = all_data[\"Validation data\"]\n",
    "    test_dataset = all_data[\"Testing data\"]\n",
    "else:\n",
    "    logging.info('Creating new datasets')\n",
    "    test_dataset, val_dataset, train_dataset = Create_Datasets(\n",
    "         data_dir+\"Video_Data/\", transformVar, test_fraction=0.15, validation_fraction=0.15, check_bad_data=False, channels=channels)\n",
    "    all_data = {\"Training data\": train_dataset, \"Validation data\": val_dataset, \"Testing data\": test_dataset}\n",
    "    save(all_data, filename_data)\n",
    "\n",
    "\n",
    "# analyser\n",
    "filename_analyser = results_dir + network_type + \"_analyser_v%03d.pickle\" % version\n",
    "if os.path.isfile(filename_analyser):\n",
    "    logging.info('Loading analyser')\n",
    "    analyser = load(filename_analyser)\n",
    "else:\n",
    "    logging.info('Creating analyser')\n",
    "    analyser = Analyser(results_dir)\n",
    "\n",
    "# Model\n",
    "filename_model = results_dir + network_type + \"_model_v%03d.pt\" % version\n",
    "if os.path.isfile(filename_model):\n",
    "    model = torch.load(filename_model)\n",
    "else:\n",
    "    model = Network(device, channels)\n",
    "\n",
    "# Learning Rate scheduler w. optimizer\n",
    "# Optimizer\n",
    "optimizer_algorithm = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "# Add learning rate schedulers\n",
    "# Decay LR by a factor of gamma every step_size epochs\n",
    "scheduler_type = 'plateau'\n",
    "if scheduler_type == 'step':\n",
    "    gamma = 0.5\n",
    "    step_size = 40\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer_algorithm, step_size=step_size, gamma=gamma)\n",
    "elif scheduler_type == 'plateau':\n",
    "    # Reduce learning rate when a metric has stopped improving\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_algorithm, mode='min', factor=0.1, patience=7)\n",
    "\n",
    "filename_metadata = results_dir + network_type + \"_metadata_v%03d.pickle\" % version\n",
    "meta_data_dict = {  \"optimizer\": optimizer_algorithm.state_dict(),\n",
    "                    \"scheduler_type\": scheduler_type, \n",
    "                    \"scheduler\": lr_scheduler.state_dict()}\n",
    "save(meta_data_dict, filename_metadata)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
    "\n",
    "root_dir = train_dataset.root_dir\n",
    "img_path = train_dataset.imagesets[0]\n",
    "im_list = sorted(listdir(root_dir + img_path[1]))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "logging.info('Experiment %d' % version)\n",
    "logging.info('Start training')\n",
    "epochs=0\n",
    "# for epoch in range(epochs):\n",
    "#     epoch_start = time.time()\n",
    "\n",
    "#     logging.info('Epoch %d' % epoch)\n",
    "#     train_epoch(model, epoch, train_dataloader, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False)\n",
    "#     \"\"\"\n",
    "#     Here we can access analyser.validation_loss to make decisions\n",
    "#     \"\"\"\n",
    "#     # Learning rate scheduler\n",
    "#     # perform scheduler step if independent from validation loss\n",
    "#     if scheduler_type == 'step':\n",
    "#         lr_scheduler.step()\n",
    "#     # perform scheduler step if Dependent on validation loss\n",
    "#     if scheduler_type == 'plateau':\n",
    "#         validation_loss = analyser.validation_loss[-1]\n",
    "#         lr_scheduler.step(validation_loss)\n",
    "#     save_network(model, filename_model)\n",
    "#     save(analyser, filename_analyser)\n",
    "\n",
    "#     epoch_time = time.time() - epoch_start \n",
    "#     logging.info('Epoch time: %.1f' % epoch_time)\n",
    "\n",
    "# analyser = []\n",
    "# model =[]\n",
    "# lr_scheduler = []\n",
    "# scheduler_dict = []\n",
    "\n",
    "# analyser.plot_loss()\n",
    "# analyser.plot_accuracy()\n",
    "# analyser.plot_loss_batchwise()\n",
    "# analyser.plot_validation_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: Ready to load batches\n",
      "Train Epoch: 1 [1/144 (1%)]\tLoss: 0.663284\tTime 29.09\n",
      "Train Epoch: 1 [2/144 (1%)]\tLoss: 0.660408\tTime 13.36\n",
      "Train Epoch: 1 [3/144 (2%)]\tLoss: 0.668999\tTime 11.84\n",
      "Train Epoch: 1 [4/144 (3%)]\tLoss: 0.624146\tTime 11.22\n",
      "Train Epoch: 1 [5/144 (3%)]\tLoss: 0.613687\tTime 11.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6/144 (4%)]\tLoss: 0.624366\tTime 12.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7/144 (5%)]\tLoss: 0.616431\tTime 12.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8/144 (6%)]\tLoss: 0.609914\tTime 11.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [9/144 (6%)]\tLoss: 0.608128\tTime 11.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10/144 (7%)]\tLoss: 0.596807\tTime 11.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [11/144 (8%)]\tLoss: 0.544661\tTime 10.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12/144 (8%)]\tLoss: 0.541056\tTime 11.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [13/144 (9%)]\tLoss: 0.543576\tTime 11.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14/144 (10%)]\tLoss: 0.547027\tTime 11.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [15/144 (10%)]\tLoss: 0.520086\tTime 10.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16/144 (11%)]\tLoss: 0.535251\tTime 12.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [17/144 (12%)]\tLoss: 0.510006\tTime 11.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [18/144 (12%)]\tLoss: 0.511077\tTime 10.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [19/144 (13%)]\tLoss: 0.494028\tTime 10.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [20/144 (14%)]\tLoss: 0.491988\tTime 10.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [21/144 (15%)]\tLoss: 0.471085\tTime 11.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [22/144 (15%)]\tLoss: 0.480037\tTime 11.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23/144 (16%)]\tLoss: 0.486340\tTime 11.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [24/144 (17%)]\tLoss: 0.447304\tTime 10.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [25/144 (17%)]\tLoss: 0.439576\tTime 11.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [26/144 (18%)]\tLoss: 0.447083\tTime 11.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [27/144 (19%)]\tLoss: 0.436873\tTime 11.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/stathis/anaconda3/envs/thesis/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-13b37e2c3f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmean_batch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch=1\n",
    "plot=False\n",
    "# def train_epoch(model, epoch, train_dataloader, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False,):\n",
    "training = True\n",
    "model.train()           # initialises training stage/functions\n",
    "mean_loss = 0\n",
    "logging.info('Training: Ready to load batches')\n",
    "for batch_num, batch in enumerate(train_dataloader):\n",
    "    batch_start = time.time()\n",
    "    # logging.info('Batch: %d loaded in %.3f' %(batch_num, batch_time))\n",
    "    mean_batch_loss = 0\n",
    "    random_starting_points = random.sample(range(100 - num_input_frames - (2 * num_output_frames) - 1), 10)\n",
    "    image_series = batch[\"image\"]\n",
    "    for i, starting_point in enumerate(random_starting_points):\n",
    "        model.reset_hidden(batch_size=image_series.size()[0], training=True)\n",
    "        lr_scheduler.optimizer.zero_grad()\n",
    "        for n in range(2 * num_output_frames):\n",
    "            if n == 0:\n",
    "                output_frames, target = initial_input(model, image_series, starting_point, num_input_frames, channels, device, training=training)\n",
    "            elif n == num_output_frames:\n",
    "                output_frames, target = new_input(model, image_series, starting_point, num_input_frames, num_output_frames, output_frames, target, channels, device, training=training)\n",
    "            else:\n",
    "                output_frames, target = consequent_propagation(model, image_series, starting_point, n, output_frames, target, channels, device, training=training)\n",
    "            if plot:\n",
    "                plot_predictions()\n",
    "        loss = F.mse_loss(output_frames, target)\n",
    "        loss.backward()\n",
    "        lr_scheduler.optimizer.step()\n",
    "        mean_batch_loss += loss.item()\n",
    "        break\n",
    "        \n",
    "    analyser.save_loss_batchwise(mean_batch_loss / (i + 1), batch_increment=1)\n",
    "    mean_loss += loss.item()\n",
    "\n",
    "    batch_time = time.time() - batch_start\n",
    "    logging.info(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime {:.2f}\".format(epoch, batch_num + 1,\n",
    "               len(train_dataloader), 100. * (batch_num + 1) / len(train_dataloader), loss.item(), batch_time ) )        \n",
    "\n",
    "    if batch_num > 3:\n",
    "        print('break')\n",
    "        break\n",
    "        \n",
    "analyser.save_loss(mean_loss / (batch_num + 1), 1)\n",
    "# val_start = time.time()\n",
    "# validation_loss = validate(model, val_dataloader, num_input_frames, num_output_frames, channels, device, plot=False)\n",
    "# analyser.save_validation_loss(validation_loss, 1)\n",
    "# val_time = time.time() - val_start\n",
    "# logging.info('Validation loss: %.6f\\tTime: %.3f' % (validation_loss, val_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Type_Network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fe012399cba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/thesis/wave_propagation/utils/Analyser.py\u001b[0m in \u001b[0;36mplot_accuracy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         sns.lineplot(x=\"Epoch\", y=\"Accuracy\",\n\u001b[1;32m     73\u001b[0m                      data=pd.DataFrame.from_dict(data), ax=fig)\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mfigure_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaindir1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Accuracy\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mType_Network\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_Project_v%03d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Type_Network' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyser.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
